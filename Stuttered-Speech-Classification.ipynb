{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtraction:\n",
    "    def __init__(self, filename, n_mels=128):\n",
    "        try:\n",
    "            if not os.path.exists(filename) or not os.path.isfile(filename):\n",
    "                raise\n",
    "            self.filename = filename\n",
    "        except:\n",
    "            sys.exit(filename + \" does not exists or is not a file\")\n",
    "        self.n_mels = n_mels\n",
    "        self.y = None\n",
    "        self.sr = None\n",
    "        self.S = None\n",
    "        self.log_S = None\n",
    "        self.mfcc = None\n",
    "        self.delta_mfcc = None\n",
    "        self.delta2_mfcc = None\n",
    "        self.M = None\n",
    "        self.rmse = None\n",
    "    \n",
    "    def loadFile(self):\n",
    "        self.y, self.sr = librosa.load(self.filename)\n",
    "    \n",
    "    def melspectrogram(self):\n",
    "        self.S = librosa.feature.melspectrogram(self.y, sr=self.sr, n_mels=self.n_mels)\n",
    "        self.log_S = librosa.logamplitude(self.S, ref_power=np.max)\n",
    "    \n",
    "    def plotmelspectrogram(self):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        librosa.display.specshow(self.log_S, sr=self.sr, x_axis='time', y_axis='mel')\n",
    "        plt.title('mel Power Spectrogram')\n",
    "        plt.colorbar(format='%+02.0f dB')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def extractmfcc(self, n_mfcc=13):\n",
    "        self.mfcc = librosa.feature.mfcc(S=self.log_S, n_mfcc=n_mfcc)\n",
    "        self.delta_mfcc = librosa.feature.delta(self.mfcc)\n",
    "        self.delta2_mfcc = librosa.feature.delta(self.mfcc, order=2)\n",
    "        self.M = np.vstack([self.mfcc, self.delta_mfcc, self.delta2_mfcc])\n",
    "    \n",
    "    def plotmfcc(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(3, 1, 1)\n",
    "        librosa.display.specshow(self.mfcc)\n",
    "        plt.ylabel('MFCC')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 2)\n",
    "        librosa.display.specshow(self.delta_mfcc)\n",
    "        plt.ylabel('MFCC-$\\Delta$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 3)\n",
    "        librosa.display.specshow(self.delta2_mfcc, sr=self.sr, x_axis='time')\n",
    "        plt.ylabel('MFCC-$\\Delta^2$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def extractrmse(self):\n",
    "        self.rmse = librosa.feature.rmse(y=self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, datasetDir, datasetLabelFilename, datasetArrayFilename):\n",
    "        try:\n",
    "            if not os.path.exists(datasetDir) or not os.path.isdir(datasetDir):\n",
    "                raise\n",
    "            self.datasetDir = datasetDir\n",
    "        except:\n",
    "            sys.exit(datasetDir + \" does not exists or is not a directory\")\n",
    "        \n",
    "        try:\n",
    "            if not os.path.exists(datasetLabelFilename) or not os.path.isfile(datasetLabelFilename):\n",
    "                raise\n",
    "            self.datasetLabelFilename = datasetLabelFilename\n",
    "        except:\n",
    "            sys.exit(datasetLabelFilename + \" does not exists or is not a file\")\n",
    "        \n",
    "        self.datasetArrayFilename = datasetArrayFilename\n",
    "        \n",
    "        self.n_features = 28\n",
    "        self.X = np.empty(shape=(0, self.n_features))\n",
    "        self.Y = np.empty(shape=(0, 2))\n",
    "        \n",
    "    \n",
    "    def build(self):\n",
    "        with open(self.datasetLabelFilename, 'r') as datasetLabelFile:\n",
    "            filesProcessed=0\n",
    "            for line in datasetLabelFile:\n",
    "                lineSplit = line.strip().split(' ')\n",
    "                audiofilename = lineSplit[0]\n",
    "                label = lineSplit[1]\n",
    "                try:\n",
    "                    features = FeatureExtraction(os.path.join(self.datasetDir, audiofilename))\n",
    "                    features.loadFile()\n",
    "                    features.melspectrogram()\n",
    "                    features.extractmfcc()\n",
    "                    features.extractrmse()\n",
    "                except ValueError:\n",
    "                    print(\"[ERROR] Error in file \" + audiofilename)\n",
    "                    continue\n",
    "                \n",
    "                featureVector = []\n",
    "                for feature in features.mfcc:\n",
    "                    featureVector.append(np.mean(feature))\n",
    "                    featureVector.append(np.var(feature))\n",
    "                \n",
    "                featureVector.append(np.mean(features.rmse))\n",
    "                featureVector.append(np.var(features.rmse))\n",
    "                \n",
    "                self.X = np.vstack((self.X, [featureVector]))\n",
    "                \n",
    "                if label == \"STUTTER\":\n",
    "                    self.Y = np.vstack((self.Y, [0, 1]))\n",
    "                elif label == \"NORMAL\":\n",
    "                    self.Y = np.vstack((self.Y, [1, 0]))\n",
    "                else:\n",
    "                    sys.exit(\"Unexpected label: \" + label)\n",
    "                \n",
    "                filesProcessed += 1\n",
    "                if filesProcessed % 1000 == 0:\n",
    "                    print(\"[INFO] Files processed:\", filesProcessed)\n",
    "            \n",
    "            print(\"-----------------------------\")\n",
    "            print(\"[INFO] Total files processed:\", filesProcessed)\n",
    "    \n",
    "    def writeToFile(self, filename=None):\n",
    "        if filename == None:\n",
    "            filename = self.datasetArrayFilename\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "        np.savetxt(filename, np.hstack((self.X, self.Y)))\n",
    "        print(\"[INFO] Array stored in file\", filename)\n",
    "    \n",
    "    def readFromFile(self, filename=None):\n",
    "        if filename == None:\n",
    "            filename = self.datasetArrayFilename\n",
    "        if not os.path.exists(filename) or not os.path.isfile(filename):\n",
    "            sys.exit(filename + \" does not exists or is not a file\")\n",
    "        matrix = np.loadtxt(filename)\n",
    "        self.X = matrix[:, 0:self.n_features]\n",
    "        self.Y = matrix[:, self.n_features:]\n",
    "        print(\"[INFO] Array read from file\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Files processed: 1000\n",
      "[INFO] Files processed: 2000\n",
      "[ERROR] Error in file M_1103_20y0m_1:241344:241344.wav\n",
      "[INFO] Files processed: 3000\n",
      "[INFO] Files processed: 4000\n",
      "[ERROR] Error in file M_1105_21y0m_1:831719:831719.wav\n",
      "[INFO] Files processed: 5000\n",
      "[INFO] Files processed: 6000\n",
      "[INFO] Files processed: 7000\n",
      "[INFO] Files processed: 8000\n",
      "[INFO] Files processed: 9000\n",
      "[INFO] Files processed: 10000\n",
      "[INFO] Files processed: 11000\n",
      "[INFO] Files processed: 12000\n",
      "-----------------------------\n",
      "[INFO] Total files processed: 12631\n",
      "[INFO] Array stored in file datasetArray.gz\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset('dataset', 'datasetLabels.txt', 'datasetArray.gz')\n",
    "if not os.path.isfile(dataset.datasetArrayFilename):\n",
    "    dataset.build()\n",
    "    dataset.writeToFile()\n",
    "else:\n",
    "    dataset.readFromFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset.X, dataset.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 800\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Model Parameters\n",
    "n_hidden_1 = 10\n",
    "n_hidden_2 = 10\n",
    "n_input = 28\n",
    "n_classes = 2\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "def network(x, weights, biases):\n",
    "    # Layer 1\n",
    "    layer1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "    \n",
    "    # Layer 2\n",
    "    layer2 = tf.add(tf.matmul(layer1, weights['h2']), biases['b2'])\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    \n",
    "    # Output layer\n",
    "    outLayer = tf.matmul(layer2, weights['out']) + biases['out']\n",
    "    \n",
    "    return outLayer\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Model\n",
    "pred = network(x, weights, biases)\n",
    "\n",
    "# Loss function and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 3070.291736359\n",
      "Epoch: 0002 cost= 790.284129041\n",
      "Epoch: 0003 cost= 425.137450685\n",
      "Epoch: 0004 cost= 305.148904354\n",
      "Epoch: 0005 cost= 217.393925525\n",
      "Epoch: 0006 cost= 155.239775475\n",
      "Epoch: 0007 cost= 110.879570251\n",
      "Epoch: 0008 cost= 89.110029464\n",
      "Epoch: 0009 cost= 74.343169882\n",
      "Epoch: 0010 cost= 60.255725252\n",
      "Epoch: 0011 cost= 47.302195468\n",
      "Epoch: 0012 cost= 38.764993749\n",
      "Epoch: 0013 cost= 32.513992857\n",
      "Epoch: 0014 cost= 27.584720378\n",
      "Epoch: 0015 cost= 23.264260911\n",
      "Epoch: 0016 cost= 19.683155648\n",
      "Epoch: 0017 cost= 16.970819643\n",
      "Epoch: 0018 cost= 14.569856547\n",
      "Epoch: 0019 cost= 12.556601574\n",
      "Epoch: 0020 cost= 10.906242033\n",
      "Epoch: 0021 cost= 9.616040619\n",
      "Epoch: 0022 cost= 8.407238945\n",
      "Epoch: 0023 cost= 7.322437154\n",
      "Epoch: 0024 cost= 6.593174744\n",
      "Epoch: 0025 cost= 5.798421340\n",
      "Epoch: 0026 cost= 5.293667549\n",
      "Epoch: 0027 cost= 4.874466521\n",
      "Epoch: 0028 cost= 4.512868695\n",
      "Epoch: 0029 cost= 3.872979541\n",
      "Epoch: 0030 cost= 3.518322268\n",
      "Epoch: 0031 cost= 3.226650126\n",
      "Epoch: 0032 cost= 3.097393295\n",
      "Epoch: 0033 cost= 2.522460424\n",
      "Epoch: 0034 cost= 2.188502037\n",
      "Epoch: 0035 cost= 2.142687817\n",
      "Epoch: 0036 cost= 1.768142694\n",
      "Epoch: 0037 cost= 1.694309741\n",
      "Epoch: 0038 cost= 1.754468719\n",
      "Epoch: 0039 cost= 2.033595502\n",
      "Epoch: 0040 cost= 1.462497951\n",
      "Epoch: 0041 cost= 1.718659879\n",
      "Epoch: 0042 cost= 1.278837170\n",
      "Epoch: 0043 cost= 1.311434190\n",
      "Epoch: 0044 cost= 1.220727596\n",
      "Epoch: 0045 cost= 1.471940339\n",
      "Epoch: 0046 cost= 1.236205596\n",
      "Epoch: 0047 cost= 1.156036085\n",
      "Epoch: 0048 cost= 1.218827569\n",
      "Epoch: 0049 cost= 1.267466278\n",
      "Epoch: 0050 cost= 1.378653328\n",
      "Epoch: 0051 cost= 1.293565042\n",
      "Epoch: 0052 cost= 1.233327501\n",
      "Epoch: 0053 cost= 1.260658674\n",
      "Epoch: 0054 cost= 1.168171939\n",
      "Epoch: 0055 cost= 1.358363506\n",
      "Epoch: 0056 cost= 1.095393392\n",
      "Epoch: 0057 cost= 1.252165517\n",
      "Epoch: 0058 cost= 1.122267445\n",
      "Epoch: 0059 cost= 1.140101014\n",
      "Epoch: 0060 cost= 1.317081865\n",
      "Epoch: 0061 cost= 1.197935881\n",
      "Epoch: 0062 cost= 1.513236258\n",
      "Epoch: 0063 cost= 1.085471459\n",
      "Epoch: 0064 cost= 0.991285071\n",
      "Epoch: 0065 cost= 1.002863086\n",
      "Epoch: 0066 cost= 1.141269617\n",
      "Epoch: 0067 cost= 1.067007705\n",
      "Epoch: 0068 cost= 1.284014051\n",
      "Epoch: 0069 cost= 1.086371227\n",
      "Epoch: 0070 cost= 1.033380572\n",
      "Epoch: 0071 cost= 0.974501580\n",
      "Epoch: 0072 cost= 1.083600701\n",
      "Epoch: 0073 cost= 0.929844806\n",
      "Epoch: 0074 cost= 1.018141691\n",
      "Epoch: 0075 cost= 0.886886428\n",
      "Epoch: 0076 cost= 0.829169530\n",
      "Epoch: 0077 cost= 0.873061694\n",
      "Epoch: 0078 cost= 0.849038359\n",
      "Epoch: 0079 cost= 0.839330737\n",
      "Epoch: 0080 cost= 0.921113658\n",
      "Epoch: 0081 cost= 0.878679252\n",
      "Epoch: 0082 cost= 0.884198671\n",
      "Epoch: 0083 cost= 0.776245231\n",
      "Epoch: 0084 cost= 0.863569649\n",
      "Epoch: 0085 cost= 0.817382051\n",
      "Epoch: 0086 cost= 0.781880100\n",
      "Epoch: 0087 cost= 0.775496456\n",
      "Epoch: 0088 cost= 0.873794039\n",
      "Epoch: 0089 cost= 0.759621821\n",
      "Epoch: 0090 cost= 0.731052954\n",
      "Epoch: 0091 cost= 0.767544173\n",
      "Epoch: 0092 cost= 0.789965601\n",
      "Epoch: 0093 cost= 0.779885834\n",
      "Epoch: 0094 cost= 0.710955691\n",
      "Epoch: 0095 cost= 0.705519381\n",
      "Epoch: 0096 cost= 0.724380510\n",
      "Epoch: 0097 cost= 0.728939194\n",
      "Epoch: 0098 cost= 0.697226431\n",
      "Epoch: 0099 cost= 0.743377493\n",
      "Epoch: 0100 cost= 0.747171165\n",
      "Optimization Finished!\n",
      "Accuracy: 0.788474\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(len(X_train) / batch_size)\n",
    "        X_batches = np.array_split(X_train, total_batch)\n",
    "        Y_batches = np.array_split(Y_train, total_batch)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: X_test, y: Y_test}))\n",
    "    global result \n",
    "    result = tf.argmax(pred, 1).eval({x: X_test, y: Y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
