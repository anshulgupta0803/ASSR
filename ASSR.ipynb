{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSR: Automatic Stuttered Speech Recoginition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "#%matplotlib inline\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import shutil\n",
    "import datetime\n",
    "import logging\n",
    "import colorlog\n",
    "import progressbar\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setting up progressbar and logger\n",
    "progressbar.streams.wrap_stderr()\n",
    "logger = colorlog.getLogger(\"ASSR\")\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(colorlog.ColoredFormatter('%(log_color)s%(levelname)-8s| %(message)s'))\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtraction:\n",
    "    def __init__(self, n_mels=128):\n",
    "        self.n_mels = n_mels\n",
    "        self.y = None\n",
    "        self.sr = None\n",
    "        self.S = None\n",
    "        self.log_S = None\n",
    "        self.mfcc = None\n",
    "        self.delta_mfcc = None\n",
    "        self.delta2_mfcc = None\n",
    "        self.M = None\n",
    "        self.rmse = None\n",
    "    \n",
    "    def loadFile(self, filename):\n",
    "        self.y, self.sr = librosa.load(filename)\n",
    "        logger.debug('File loaded: %s', filename)\n",
    "    \n",
    "    def load_y_sr(self, y, sr):\n",
    "        self.y = y\n",
    "        self.sr = sr\n",
    "    \n",
    "    def melspectrogram(self):\n",
    "        self.S = librosa.feature.melspectrogram(self.y, sr=self.sr, n_mels=self.n_mels)\n",
    "        self.log_S = librosa.logamplitude(self.S, ref_power=np.max)\n",
    "    \n",
    "    def plotmelspectrogram(self):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        librosa.display.specshow(self.log_S, sr=self.sr, x_axis='time', y_axis='mel')\n",
    "        plt.title('mel Power Spectrogram')\n",
    "        plt.colorbar(format='%+02.0f dB')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def extractmfcc(self, n_mfcc=13):\n",
    "        self.mfcc = librosa.feature.mfcc(S=self.log_S, n_mfcc=n_mfcc)\n",
    "        self.delta_mfcc = librosa.feature.delta(self.mfcc)\n",
    "        self.delta2_mfcc = librosa.feature.delta(self.mfcc, order=2)\n",
    "        self.M = np.vstack([self.mfcc, self.delta_mfcc, self.delta2_mfcc])\n",
    "    \n",
    "    def plotmfcc(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(3, 1, 1)\n",
    "        librosa.display.specshow(self.mfcc)\n",
    "        plt.ylabel('MFCC')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 2)\n",
    "        librosa.display.specshow(self.delta_mfcc)\n",
    "        plt.ylabel('MFCC-$\\Delta$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(3, 1, 3)\n",
    "        librosa.display.specshow(self.delta2_mfcc, sr=self.sr, x_axis='time')\n",
    "        plt.ylabel('MFCC-$\\Delta^2$')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    def extractrmse(self):\n",
    "        self.rmse = librosa.feature.rmse(y=self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, datasetDir, datasetLabelFilename, datasetArrayFilename):\n",
    "        self.n_features = 80\n",
    "        logger.info(\"Number of features: %s\", self.n_features)\n",
    "        self.X = np.empty(shape=(0, self.n_features))\n",
    "        self.Y = np.empty(shape=(0, 2))\n",
    "        \n",
    "        self.datasetArrayFilename = datasetArrayFilename\n",
    "        logger.debug(\"Dataset array filename: %s\", self.datasetArrayFilename)\n",
    "        \n",
    "        if os.path.isfile(self.datasetArrayFilename):    \n",
    "            self.__readFromFile()\n",
    "        else:\n",
    "            self.datasetDir = datasetDir\n",
    "            logger.debug(\"Dataset Directory: %s\", self.datasetDir)\n",
    "\n",
    "            self.datasetLabelFilename = datasetLabelFilename\n",
    "            logger.debug(\"Dataset labels filename: %s\", self.datasetLabelFilename)\n",
    "\n",
    "            if not os.path.isdir(self.datasetDir) or not os.path.isfile(self.datasetLabelFilename):\n",
    "                logger.info(\"%s or %s does not exists\", self.datasetDir, self.datasetLabelFilename)\n",
    "                self.__buildDatasetAndLabels('wav/release1')\n",
    "                \n",
    "            self.__build()\n",
    "            self.__writeToFile()\n",
    "    \n",
    "    def __build(self):\n",
    "        logger.info(\"Building dataset from directory: %s\", self.datasetDir)\n",
    "        num_lines = sum(1 for line in open(self.datasetLabelFilename, 'r'))\n",
    "        with open(self.datasetLabelFilename, 'r') as datasetLabelFile:\n",
    "            filesProcessed=0\n",
    "            pbar = progressbar.ProgressBar(redirect_stdout=True)\n",
    "            for line in pbar(datasetLabelFile, max_value=num_lines):\n",
    "                lineSplit = line.strip().split(' ')\n",
    "                audiofilename = lineSplit[0]\n",
    "                label = lineSplit[1]\n",
    "                try:\n",
    "                    features = FeatureExtraction()\n",
    "                    features.loadFile(os.path.join(self.datasetDir, audiofilename))\n",
    "                    features.melspectrogram()\n",
    "                    features.extractmfcc()\n",
    "                    features.extractrmse()\n",
    "                except ValueError:\n",
    "                    logger.warning(\"Error in extracting features from file %s\", audiofilename)\n",
    "                    continue\n",
    "                \n",
    "                featureVector = []\n",
    "                for feature in features.mfcc:\n",
    "                    featureVector.append(np.mean(feature))\n",
    "                    featureVector.append(np.var(feature))\n",
    "                \n",
    "                for feature in features.delta_mfcc:\n",
    "                    featureVector.append(np.mean(feature))\n",
    "                    featureVector.append(np.var(feature))\n",
    "                \n",
    "                for feature in features.delta2_mfcc:\n",
    "                    featureVector.append(np.mean(feature))\n",
    "                    featureVector.append(np.var(feature))\n",
    "                \n",
    "                featureVector.append(np.mean(features.rmse))\n",
    "                featureVector.append(np.var(features.rmse))\n",
    "                \n",
    "                self.X = np.vstack((self.X, [featureVector]))\n",
    "                \n",
    "                if label == \"STUTTER\":\n",
    "                    self.Y = np.vstack((self.Y, [0, 1]))\n",
    "                elif label == \"NORMAL\":\n",
    "                    self.Y = np.vstack((self.Y, [1, 0]))\n",
    "                else:\n",
    "                    logger.error(\"Unexpected label: %s\", label)\n",
    "                    sys.exit()\n",
    "                \n",
    "                filesProcessed += 1            \n",
    "            \n",
    "            logger.info(\"Total files processed: %d\", filesProcessed)\n",
    "    \n",
    "    def __buildDatasetAndLabels(self, audioAndChaFilesDirectory):\n",
    "        logger.info(\"Rebuilding the dataset directory and labels\")\n",
    "        if os.path.isdir(self.datasetDir):\n",
    "            shutil.rmtree(self.datasetDir)\n",
    "        os.makedirs(self.datasetDir)\n",
    "        \n",
    "        labelFile = open(self.datasetLabelFilename, 'w')\n",
    "        \n",
    "        splitDuration = 300 # milliseconds\n",
    "        pbar = progressbar.ProgressBar(redirect_stdout=True)\n",
    "        for chaFileName in pbar(os.listdir(audioAndChaFilesDirectory)):\n",
    "            if chaFileName.endswith(\".cha\"):\n",
    "                subject = chaFileName.split('.')[0]\n",
    "                wavFileName = subject + \".wav\"\n",
    "                y, sr = librosa.load(os.path.join(audioAndChaFilesDirectory, wavFileName))\n",
    "\n",
    "                logger.debug(\"Parsing file: %s\", chaFileName)\n",
    "\n",
    "                with open(os.path.join(audioAndChaFilesDirectory, chaFileName), 'r') as chaFile:\n",
    "                    sndFound = False\n",
    "                    phoFound = False\n",
    "                    startTime = -1\n",
    "                    endTime = -1\n",
    "                    label = None\n",
    "                    for line in chaFile:\n",
    "                        if not sndFound:\n",
    "                            if re.search(r\"%snd:\", line):\n",
    "                                lineSplit = line.split(\"_\")\n",
    "                                startTime = int(lineSplit[-2])\n",
    "                                endTime = lineSplit[-1]\n",
    "                                endTime = int(re.sub(r\"\\u0015\\n\", '', endTime))\n",
    "                                sndFound = True\n",
    "                        else:\n",
    "                            if re.search(r\"%pho:\", line):\n",
    "                                if re.search(r'[A-Z]', line):\n",
    "                                    label = \"STUTTER\"\n",
    "                                else:\n",
    "                                    label = \"NORMAL\"\n",
    "                                phoFound = True\n",
    "                        if sndFound and phoFound:\n",
    "                            n_splits = int(np.round((endTime - startTime) / splitDuration))\n",
    "                            \n",
    "                            startingSample = int(startTime * sr / 1000)\n",
    "                            for i in range(1, n_splits):\n",
    "                                endingSample = int(startingSample + (splitDuration * sr / 1000))\n",
    "                                audiofilename = subject + \":\" + str(startTime) + \":\" + str(int(startTime) + splitDuration) + \".wav\"\n",
    "                                labelFile.write(audiofilename + \" \" + label + \"\\n\")\n",
    "                                audio = y[startingSample:endingSample]\n",
    "                                librosa.output.write_wav(os.path.join(self.datasetDir, audiofilename), audio, sr)\n",
    "                                \n",
    "                                startingSample = endingSample\n",
    "                                startTime = int(startTime) + splitDuration\n",
    "                            \n",
    "                            endingSample = int(endTime * sr / 1000)\n",
    "                            audiofilename = subject + \":\" + str(startTime) + \":\" + str(endTime) + \".wav\"\n",
    "                            labelFile.write(audiofilename + \" \" + label + \"\\n\")\n",
    "                            audio = y[startingSample:endingSample]\n",
    "                            librosa.output.write_wav(os.path.join(self.datasetDir, audiofilename), audio, sr)\n",
    "                            \n",
    "                            \n",
    "                            sndFound = False\n",
    "                            phoFound = False\n",
    "                            startTime = -1\n",
    "                            endTime = -1\n",
    "                            label = None\n",
    "\n",
    "        labelFile.close()\n",
    "    \n",
    "    def __writeToFile(self, filename=None):\n",
    "        if filename == None:\n",
    "            filename = self.datasetArrayFilename\n",
    "            \n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "        np.savetxt(filename, np.hstack((self.X, self.Y)))\n",
    "        logger.info(\"Array stored in file %s\", filename)\n",
    "    \n",
    "    def __readFromFile(self, filename=None):\n",
    "        if filename == None:\n",
    "            filename = self.datasetArrayFilename\n",
    "            \n",
    "        if not os.path.isfile(filename):\n",
    "            logger.error(\"%s does not exists or is not a file\", filename)\n",
    "            sys.exit()\n",
    "        matrix = np.loadtxt(filename)\n",
    "        self.X = matrix[:, 0:self.n_features]\n",
    "        self.Y = matrix[:, self.n_features:]\n",
    "        logger.info(\"Array read from file %s\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, X_train=None, Y_train=None, X_test=None, Y_test=None):\n",
    "        # Data\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        \n",
    "        # Learning Parameters\n",
    "        self.learning_rate = 0.001\n",
    "        self.training_epochs = 1200\n",
    "        self.batch_size = 100\n",
    "        self.display_step = 100\n",
    "\n",
    "        # Model Parameters\n",
    "        self.n_hidden = [10, 10, 10]\n",
    "        self.hiddenLayers = len(self.n_hidden)\n",
    "        self.n_input = 80\n",
    "        self.n_classes = 2\n",
    "\n",
    "        logger.debug(\"Neural network of depth %d\", self.hiddenLayers)\n",
    "        for i in range(self.hiddenLayers):\n",
    "            logger.debug(\"Depth of layer %d is %d\", (i + 1), self.n_hidden[i])\n",
    "\n",
    "        self.x = tf.placeholder(\"float\", [None, self.n_input])\n",
    "        self.y = tf.placeholder(\"float\", [None, self.n_classes])\n",
    "        self.layer = None\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        # Model\n",
    "        self.model = self.__network(self.x)\n",
    "        self.save_path = None\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.model, labels=self.y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "        # Initialize the variables\n",
    "        self.init = tf.global_variables_initializer()\n",
    "    \n",
    "    def setTrainData(self, X, Y):\n",
    "        self.X_train = X\n",
    "        self.Y_train = Y\n",
    "        \n",
    "    def setTestData(self, X, Y):\n",
    "        self.X_test = X\n",
    "        self.Y_test = Y\n",
    "        \n",
    "    def __network(self, x):\n",
    "        self.layer = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        for n_layer in range(self.hiddenLayers):\n",
    "            if n_layer == 0:\n",
    "                self.weights.append(tf.Variable(tf.random_normal([self.n_input, self.n_hidden[n_layer]])))\n",
    "                self.biases.append(tf.Variable(tf.random_normal([self.n_hidden[n_layer]])))\n",
    "                self.layer.append(tf.nn.relu(tf.add(tf.matmul(x, self.weights[n_layer]), self.biases[n_layer])))\n",
    "            else:\n",
    "                self.weights.append(tf.Variable(tf.random_normal([self.n_hidden[n_layer - 1], self.n_hidden[n_layer]])))\n",
    "                self.biases.append(tf.Variable(tf.random_normal([self.n_hidden[n_layer]])))\n",
    "                self.layer.append(tf.nn.relu(tf.add(tf.matmul(self.layer[n_layer - 1], self.weights[n_layer]), self.biases[n_layer])))\n",
    "\n",
    "\n",
    "        # Output layer\n",
    "        self.weights.append(tf.Variable(tf.random_normal([self.n_hidden[self.hiddenLayers - 1], self.n_classes])))\n",
    "        self.biases.append(tf.Variable(tf.random_normal([self.n_classes])))\n",
    "        self.layer.append(tf.matmul(self.layer[self.hiddenLayers - 1], self.weights[self.hiddenLayers]) + self.biases[self.hiddenLayers])\n",
    "\n",
    "        return self.layer[self.hiddenLayers]\n",
    "    \n",
    "    def train(self):\n",
    "        logger.info(\"Training the neural network\")\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(self.init)\n",
    "            pbarWidgets = [\n",
    "                progressbar.Percentage(),\n",
    "                ' (',\n",
    "                progressbar.SimpleProgress(),\n",
    "                ') ',\n",
    "                progressbar.Bar(),\n",
    "                ' ',\n",
    "                progressbar.Timer(),\n",
    "                ' ',\n",
    "                progressbar.ETA(),\n",
    "                ' ',\n",
    "                progressbar.DynamicMessage('Cost'),\n",
    "            ]\n",
    "            with progressbar.ProgressBar(max_value=self.training_epochs, redirect_stdout=True, widgets=pbarWidgets) as pbar:\n",
    "                for epoch in range(self.training_epochs):\n",
    "                    avg_cost = 0\n",
    "                    total_batch = int(len(self.X_train) / self.batch_size)\n",
    "                    X_batches = np.array_split(self.X_train, total_batch)\n",
    "                    Y_batches = np.array_split(self.Y_train, total_batch)\n",
    "\n",
    "                    for i in range(total_batch):\n",
    "                        batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "                        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                        _, c = sess.run([self.optimizer, self.cost], feed_dict={self.x: batch_x, self.y: batch_y})\n",
    "\n",
    "                        # Compute average loss\n",
    "                        avg_cost += c / total_batch\n",
    "\n",
    "                    pbar.update(epoch + 1, Cost=avg_cost)\n",
    "                \n",
    "            logger.info(\"Optimization Finished!\")\n",
    "\n",
    "            evalAccuracy = self.__getAccuracy()\n",
    "            \n",
    "            global result \n",
    "            result = tf.argmax(self.model, 1).eval({self.x: X_test, self.y: Y_test})\n",
    "            \n",
    "            tfSessionsDir = \"tfSessions\"\n",
    "            if not os.path.isdir(tfSessionsDir):\n",
    "                os.makedirs(tfSessionsDir)\n",
    "            timestamp = '{:%Y-%m-%d-%H:%M:%S}'.format(datetime.datetime.now()) + '-' + str(evalAccuracy)\n",
    "            os.makedirs(os.path.join(tfSessionsDir, timestamp))\n",
    "            modelfilename =  os.path.join(os.path.join(tfSessionsDir, timestamp), 'session.ckpt')\n",
    "            self.save_path = saver.save(sess, modelfilename)\n",
    "            \n",
    "            with open(os.path.join(os.path.join(tfSessionsDir, timestamp), 'details.txt'), 'w') as details:\n",
    "                details.write(\"learning_rate = \" + str(self.learning_rate) + \"\\n\")\n",
    "                details.write(\"training_epochs = \" + str(self.training_epochs) + \"\\n\")\n",
    "                details.write(\"batch_size = \" + str(self.batch_size) + \"\\n\")\n",
    "                details.write(\"display_step = \" + str(self.display_step) + \"\\n\")\n",
    "                details.write(\"n_hidden = \" + str(self.n_hidden) + \"\\n\")\n",
    "                details.write(\"hiddenLayers = \" + str(self.hiddenLayers) + \"\\n\")\n",
    "                details.write(\"n_input = \" + str(self.n_input) + \"\\n\")\n",
    "                details.write(\"n_classes = \" + str(self.n_classes) + \"\\n\")\n",
    "                \n",
    "            logger.info(\"Model saved in file: %s\" % self.save_path)\n",
    "    \n",
    "    def getModelPath(self):\n",
    "        return self.save_path\n",
    "        \n",
    "    def __getAccuracy(self):\n",
    "        # Test model\n",
    "        correct_prediction = tf.equal(tf.argmax(self.model, 1), tf.argmax(self.y, 1))\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        evalAccuracy = accuracy.eval({self.x: self.X_test, self.y: self.Y_test})\n",
    "        logger.info(\"Accuracy: %f\", evalAccuracy)\n",
    "        return evalAccuracy\n",
    "        \n",
    "    def loadAndClassify(self, filename, X):            \n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            saver.restore(sess, filename)\n",
    "            prediction_model = tf.argmax(self.model, 1)\n",
    "            return prediction_model.eval({self.x: X})\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using the NN model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCorrection():\n",
    "    def __init__(self, audiofile, tfSessionFile, segmentLength=300, segmentHop=100, n_features=80, correctionsDir='corrections'):\n",
    "        self.tfSessionFile = tfSessionFile\n",
    "        self.segmentLength = segmentLength\n",
    "        self.segmentHop = segmentHop\n",
    "        self.n_features = n_features\n",
    "        self.correctionsDir = correctionsDir\n",
    "        self.samplesPerSegment = None\n",
    "        self.samplesToSkipPerHop = None\n",
    "        self.upperLimit = None\n",
    "        self.inputFilename = None\n",
    "        self.y = None\n",
    "        self.sr = None\n",
    "        self.target_sr = 16000\n",
    "        NORMAL = 0\n",
    "        STUTTER = 1\n",
    "        self.speech = {NORMAL: [], STUTTER: []}\n",
    "        self.smoothingSamples = 1000\n",
    "        self.__loadfile(audiofile)\n",
    "    \n",
    "    def __loadfile(self, inputFilename):\n",
    "        if not os.path.isfile(inputFilename):\n",
    "            logger.error(\"%s does not exists or is not a file\", inputFilename)\n",
    "            sys.exit()\n",
    "        self.inputFilename = inputFilename\n",
    "        logger.info(\"Loading file %s\", self.inputFilename)\n",
    "        self.y, self.sr = librosa.load(self.inputFilename)\n",
    "        self.samplesPerSegment = int(self.segmentLength * self.sr / 1000)\n",
    "        self.samplesToSkipPerHop = int(self.segmentHop * self.sr / 1000)\n",
    "        self.upperLimit = len(self.y) - self.samplesPerSegment\n",
    "\n",
    "    def process(self):\n",
    "        logger.info(\"Attempting to correct %s\", self.inputFilename)\n",
    "        X = np.empty(shape=(0, self.n_features))\n",
    "        durations = np.empty(shape=(0, 2))\n",
    "\n",
    "        pbar = progressbar.ProgressBar()\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for start in pbar(range(0, self.upperLimit, self.samplesToSkipPerHop)):\n",
    "            end = start + self.samplesPerSegment\n",
    "            audio = self.y[start:end]\n",
    "\n",
    "            featureVector = self.__getFeatureVector(audio, self.sr)\n",
    "            if featureVector != None:\n",
    "                X = np.vstack((X, [featureVector]))\n",
    "                durations = np.vstack((durations, [start, end]))\n",
    "        \n",
    "        audio = self.y[end:]\n",
    "        featureVector = self.__getFeatureVector(audio, self.sr)\n",
    "        if featureVector != None:\n",
    "            X = np.vstack((X, [featureVector]))\n",
    "            durations = np.vstack((durations, [end, self.upperLimit + self.samplesPerSegment]))\n",
    "        logger.debug(\"Finished extracting features\")\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        nn = NeuralNetwork()\n",
    "        classificationResult = nn.loadAndClassify(self.tfSessionFile, X)\n",
    "        logger.debug(\"Finished classification of segments\")\n",
    "        \n",
    "        currentSegment = {'type': classificationResult[0], 'start': durations[0][0], 'end': durations[0][1]}\n",
    "        for (label, [start, end]) in zip(classificationResult[1:], durations[1:]):\n",
    "            if currentSegment['type'] == label:\n",
    "                currentSegment['end'] = end\n",
    "            else:\n",
    "                self.speech[currentSegment['type']].append((currentSegment['start'], currentSegment['end']))\n",
    "                currentSegment['type'] = label\n",
    "                currentSegment['start'] = start\n",
    "                currentSegment['end'] = end\n",
    "    \n",
    "    def __getFeatureVector(self, y, sr):\n",
    "        try:\n",
    "            features = FeatureExtraction()\n",
    "            features.load_y_sr(y, sr)\n",
    "            features.melspectrogram()\n",
    "            features.extractmfcc()\n",
    "            features.extractrmse()\n",
    "        except ValueError:\n",
    "            logger.warning(\"Error extracting features\")\n",
    "            return None\n",
    "\n",
    "        featureVector = []\n",
    "        for feature in features.mfcc:\n",
    "            featureVector.append(np.mean(feature))\n",
    "            featureVector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta_mfcc:\n",
    "            featureVector.append(np.mean(feature))\n",
    "            featureVector.append(np.var(feature))\n",
    "\n",
    "        for feature in features.delta2_mfcc:\n",
    "            featureVector.append(np.mean(feature))\n",
    "            featureVector.append(np.var(feature))\n",
    "\n",
    "        featureVector.append(np.mean(features.rmse))\n",
    "        featureVector.append(np.var(features.rmse))\n",
    "        \n",
    "        return featureVector\n",
    "    \n",
    "    def saveCorrectedAudio(self):\n",
    "        NORMAL = 0\n",
    "        STUTTER = 1\n",
    "        if not os.path.isdir(self.correctionsDir):\n",
    "            os.makedirs(self.correctionsDir)\n",
    "        outputFilenamePrefix = os.path.join(self.correctionsDir, os.path.splitext(os.path.basename(self.inputFilename))[0])\n",
    "        \n",
    "        normalSpeech = np.ndarray(shape=(1, 0))\n",
    "        (start, end) = self.speech[NORMAL][0]\n",
    "        normalSpeech = np.append(normalSpeech, self.y[int(start):int(end)])\n",
    "        for (start, end) in self.speech[NORMAL][1:]:\n",
    "            # Smoothing\n",
    "            previousSample = normalSpeech[-1]\n",
    "            nextSample = self.y[int(start)]\n",
    "            if nextSample > previousSample:\n",
    "                low, high = previousSample, nextSample\n",
    "            else:\n",
    "                low, high = nextSample, previousSample\n",
    "            \n",
    "            step = (high - low) / self.smoothingSamples\n",
    "            \n",
    "            normalSpeech = np.append(normalSpeech, np.arange(low, high, step))\n",
    "            normalSpeech = np.append(normalSpeech, self.y[int(start):int(end)])\n",
    "\n",
    "        stutteredSpeech = np.ndarray(shape=(1, 0))\n",
    "        for (start, end) in self.speech[STUTTER]:\n",
    "            stutteredSpeech = np.append(stutteredSpeech, self.y[int(start):int(end)])\n",
    "\n",
    "        # Resampling the audio\n",
    "        logger.debug(\"Resampling corrected audio from %d to %d\", self.sr, self.target_sr)\n",
    "        resampledNormalSpeech = librosa.resample(normalSpeech, self.sr, self.target_sr)\n",
    "        resampledStutteredSpeech = librosa.resample(stutteredSpeech, self.sr, self.target_sr)\n",
    "        librosa.output.write_wav(outputFilenamePrefix + \"-corrected.wav\", normalSpeech, self.sr)\n",
    "        librosa.output.write_wav(outputFilenamePrefix + \"-stuttered.wav\", stutteredSpeech, self.sr)\n",
    "        logger.info(\"Corrected audio saved as %s\", outputFilenamePrefix + \"-corrected.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(train=False, correct=False):\n",
    "    if train:\n",
    "        dataset = Dataset('dataset', 'datasetLabels.txt', 'datasetArray80.gz')\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(dataset.X, dataset.Y)\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        nn = NeuralNetwork(X_train, Y_train, X_test, Y_test)\n",
    "        nn.train()\n",
    "\n",
    "    if correct:\n",
    "        audiofile = 'M_0219_11y2m_1.wav'\n",
    "        if train:\n",
    "            tfSessionFile = nn.getModelPath()\n",
    "        else:\n",
    "            tfSessionFile = 'tfSessions/2017-11-26-20:08:45-0.870725/session.ckpt'\n",
    "\n",
    "        correction = AudioCorrection(audiofile, tfSessionFile)\n",
    "        correction.process()\n",
    "        correction.saveCorrectedAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run(False, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
